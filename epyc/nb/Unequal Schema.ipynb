{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7746e435",
   "metadata": {},
   "source": [
    "# Unequal schema problems\n",
    "\n",
    "There are a few ways in which parquet files written with slightly different schema can cause issues in the import pipeline. They have a similar correction mechanism, so we discuss both here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca67a33",
   "metadata": {},
   "source": [
    "### Approaching \"Unsupported cast\" errors\n",
    "\n",
    "Occasionally, an import will throw errors like the following:\n",
    "\n",
    "```\n",
    "Key:       4_2666\n",
    "Function:  reduce_pixel_shards\n",
    "args:      ()\n",
    "kwargs:    {...}\n",
    "Exception: \"ArrowNotImplementedError('Unsupported cast from string to null using function cast_null')\"\n",
    "```\n",
    "\n",
    "We've observed that this is due to the way that PyArrow encodes types in parquet files.\n",
    "\n",
    "At the reduce stage, we're combining several intermediate parquet files for a single spatial tile into the final parquet file. It's possible at this stage that some files will contain only empty (null) values in a column that we expect to be a string field.\n",
    "\n",
    "e.g. \n",
    "\n",
    "#### File1\n",
    "\n",
    "| int_field | string_field | float_field |\n",
    "| --------- | ------------ | ----------  |\n",
    "|         5 |      <empty> |         3.4 |\n",
    "|         8 |      <empty> |         3.8 |\n",
    "\n",
    "which will have a schema like:\n",
    "       \n",
    "    optional int64 field_id=-1 int_field;\n",
    "    optional int32 field_id=-1 string_field **(Null)**;\n",
    "    optional double field_id=-1 float_field;\n",
    "    \n",
    "#### File2\n",
    "    \n",
    "| int_field | string_field | float_field |\n",
    "| --------- |------------- | ----------- |\n",
    "|         6 |      hello   |         4.1 |\n",
    "|         7 |      <empty> |         3.9 |\n",
    "\n",
    "will have a schema like:\n",
    "\n",
    "    optional int64 field_id=-1 int_field;\n",
    "    optional binary field_id=-1 string_field (String);\n",
    "    optional double field_id=-1 float_field;\n",
    "\n",
    "When we try to merge these files together, the parquet engine does not want to perform a cast between these types, and throws an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76dc72c",
   "metadata": {},
   "source": [
    "### Approaching unequal schema\n",
    "\n",
    "In the final stages of the import pipeline, we create a top-level parquet metadata file that includes the full schema for the dataset (`_common_metadata`). This expects that **all** parquet files have the same column-level schema.\n",
    "\n",
    "If one or more files are misbehaving, this can cause the whole pipeline to fail, and in order to succeed, the files will need to be re-written using a standard parquet schema. We have found that this is caused by similar data discrepancies to the above case, but the issue can surface in different ways depending on the shape of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7925b",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "In this notebook, we will look at finding those misbehaving parquet files and generating a single standard parquet schema file to use when writing the dataset.\n",
    "\n",
    "The first stage shows how to explore the datasets and see what fields are potentially causing issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c74cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 3768 parquet files\n",
      "first file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=2/Dir=0/Npix=0.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=5/Dir=0/Npix=3589.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=5/Dir=0/Npix=3633.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=5/Dir=0/Npix=8030.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=5/Dir=0/Npix=8031.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=5/Dir=0/Npix=8049.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=5/Dir=0/Npix=8052.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=5/Dir=0/Npix=8053.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=10000/Npix=14344.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=10000/Npix=14345.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=10000/Npix=14346.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=10000/Npix=14361.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=10000/Npix=14388.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=10000/Npix=14447.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=10000/Npix=14458.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28674.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28677.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28678.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28679.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28680.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28681.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28682.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28685.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28690.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28695.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28696.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28744.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28760.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28771.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28772.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28787.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28790.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28793.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28796.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28821.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28864.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=20000/Npix=28986.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=40000/Npix=42327.parquet\n",
      "mismatch file\n",
      "/data3/epyc/data3/hipscat/catalogs/tic_1/Norder=6/Dir=40000/Npix=42333.parquet\n",
      "compared 3730 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "## list all of our parquet data files\n",
    "\n",
    "catalog_dir = \"/data3/epyc/data3/hipscat/catalogs/tic_1/\"\n",
    "all_files = glob.glob(os.path.join(catalog_dir, \"**/**/**.parquet\"))\n",
    "# catalog_dir = \"/epyc/data/ztf_matchfiles/zubercal_dr16/atua.caltech.edu/F3215/\"\n",
    "# all_files = glob.glob(os.path.join(catalog_dir, \"**.parquet\"))\n",
    "print(f'found {len(all_files)} parquet files')\n",
    "all_files.sort()\n",
    "\n",
    "## Find the first pair of differences\n",
    "file_name = all_files[0]\n",
    "md1 = pq.read_metadata(file_name)\n",
    "print(\"first file\")\n",
    "print(file_name)\n",
    "\n",
    "num_equal = 1\n",
    "for file_name in all_files[1:]:\n",
    "    md2 = pq.read_metadata(file_name)\n",
    "\n",
    "    if not md1.schema.equals(md2.schema):\n",
    "        print(\"mismatch file\")\n",
    "        print(file_name)\n",
    "        \n",
    "#         print(md1.schema)\n",
    "#         print(md2.schema)\n",
    "#         break\n",
    "    else: num_equal+=1\n",
    "\n",
    "print(f\"compared {num_equal} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192664a",
   "metadata": {},
   "source": [
    "**Read a single input file**\n",
    "\n",
    "Start by reading a single input file as a pandas dataframe. You can reuse the InputReader class that you've instantiated for the import pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b063560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>version</th>\n",
       "      <th>HIP</th>\n",
       "      <th>TYC</th>\n",
       "      <th>UCAC</th>\n",
       "      <th>TWOMASS</th>\n",
       "      <th>SDSS</th>\n",
       "      <th>ALLWISE</th>\n",
       "      <th>GAIA</th>\n",
       "      <th>APASS</th>\n",
       "      <th>...</th>\n",
       "      <th>splists</th>\n",
       "      <th>e_RA</th>\n",
       "      <th>e_Dec</th>\n",
       "      <th>RA_orig</th>\n",
       "      <th>Dec_orig</th>\n",
       "      <th>e_RA_orig</th>\n",
       "      <th>e_Dec_orig</th>\n",
       "      <th>raddflag</th>\n",
       "      <th>wdflag</th>\n",
       "      <th>objID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421102183</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17261819-5512067</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5922830166853154944</td>\n",
       "      <td>29366166</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.040034</td>\n",
       "      <td>5.723953</td>\n",
       "      <td>261.575979</td>\n",
       "      <td>-55.201992</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1244322854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421229958</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17270117-5439406</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>J172701.26-543942.1</td>\n",
       "      <td>5922959054539196800</td>\n",
       "      <td>25407987</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.501635</td>\n",
       "      <td>2.143100</td>\n",
       "      <td>261.754774</td>\n",
       "      <td>-54.661488</td>\n",
       "      <td>0.086798</td>\n",
       "      <td>0.082517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1247347547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421230090</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17271673-5437554</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>J172716.75-543755.7</td>\n",
       "      <td>5922964895681108992</td>\n",
       "      <td>25408261</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.738124</td>\n",
       "      <td>2.371065</td>\n",
       "      <td>261.819850</td>\n",
       "      <td>-54.631986</td>\n",
       "      <td>0.130497</td>\n",
       "      <td>0.091899</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1248828237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>421228714</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176-197391</td>\n",
       "      <td>17270502-5457554</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>J172705.23-545754.1</td>\n",
       "      <td>5922859857961061760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.549063</td>\n",
       "      <td>3.928844</td>\n",
       "      <td>261.770905</td>\n",
       "      <td>-54.965539</td>\n",
       "      <td>0.146773</td>\n",
       "      <td>0.146296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1247346996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>421098618</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17260598-5418155</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>J172605.95-541815.9</td>\n",
       "      <td>5923042857934705280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.995923</td>\n",
       "      <td>6.302023</td>\n",
       "      <td>261.525699</td>\n",
       "      <td>-54.304340</td>\n",
       "      <td>0.307969</td>\n",
       "      <td>0.232219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1244321199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1044757491</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6063861126032459136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.085994</td>\n",
       "      <td>13.512841</td>\n",
       "      <td>201.222372</td>\n",
       "      <td>-55.945179</td>\n",
       "      <td>0.125915</td>\n",
       "      <td>0.326936</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>848094308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1046515676</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6067114336119961216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.718694</td>\n",
       "      <td>7.443775</td>\n",
       "      <td>202.040730</td>\n",
       "      <td>-54.277964</td>\n",
       "      <td>0.256131</td>\n",
       "      <td>0.286796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>853812771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1046750717</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6068601910926032512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.734570</td>\n",
       "      <td>15.305327</td>\n",
       "      <td>202.492182</td>\n",
       "      <td>-54.246797</td>\n",
       "      <td>0.577675</td>\n",
       "      <td>0.490129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>853813897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1044730684</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6063812953698211456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.195783</td>\n",
       "      <td>1.148171</td>\n",
       "      <td>202.738866</td>\n",
       "      <td>-55.257337</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.030967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>855564392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1044654927</td>\n",
       "      <td>20190415</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6063716398513267968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.030988</td>\n",
       "      <td>6.196191</td>\n",
       "      <td>202.765541</td>\n",
       "      <td>-55.994185</td>\n",
       "      <td>0.104035</td>\n",
       "      <td>0.151344</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>854308407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID   version   HIP  TYC        UCAC           TWOMASS  SDSS   \n",
       "0       421102183  20190415  <NA>  NaN         NaN  17261819-5512067  <NA>  \\\n",
       "1       421229958  20190415  <NA>  NaN         NaN  17270117-5439406  <NA>   \n",
       "2       421230090  20190415  <NA>  NaN         NaN  17271673-5437554  <NA>   \n",
       "3       421228714  20190415  <NA>  NaN  176-197391  17270502-5457554  <NA>   \n",
       "4       421098618  20190415  <NA>  NaN         NaN  17260598-5418155  <NA>   \n",
       "...           ...       ...   ...  ...         ...               ...   ...   \n",
       "49995  1044757491  20190415  <NA>  NaN         NaN               NaN  <NA>   \n",
       "49996  1046515676  20190415  <NA>  NaN         NaN               NaN  <NA>   \n",
       "49997  1046750717  20190415  <NA>  NaN         NaN               NaN  <NA>   \n",
       "49998  1044730684  20190415  <NA>  NaN         NaN               NaN  <NA>   \n",
       "49999  1044654927  20190415  <NA>  NaN         NaN               NaN  <NA>   \n",
       "\n",
       "                   ALLWISE                 GAIA     APASS  ...  splists   \n",
       "0                      NaN  5922830166853154944  29366166  ...      NaN  \\\n",
       "1      J172701.26-543942.1  5922959054539196800  25407987  ...      NaN   \n",
       "2      J172716.75-543755.7  5922964895681108992  25408261  ...      NaN   \n",
       "3      J172705.23-545754.1  5922859857961061760       NaN  ...      NaN   \n",
       "4      J172605.95-541815.9  5923042857934705280       NaN  ...      NaN   \n",
       "...                    ...                  ...       ...  ...      ...   \n",
       "49995                  NaN  6063861126032459136       NaN  ...      NaN   \n",
       "49996                  NaN  6067114336119961216       NaN  ...      NaN   \n",
       "49997                  NaN  6068601910926032512       NaN  ...      NaN   \n",
       "49998                  NaN  6063812953698211456       NaN  ...      NaN   \n",
       "49999                  NaN  6063716398513267968       NaN  ...      NaN   \n",
       "\n",
       "            e_RA      e_Dec     RA_orig   Dec_orig e_RA_orig  e_Dec_orig   \n",
       "0       6.040034   5.723953  261.575979 -55.201992  0.189400    0.213219  \\\n",
       "1       2.501635   2.143100  261.754774 -54.661488  0.086798    0.082517   \n",
       "2       2.738124   2.371065  261.819850 -54.631986  0.130497    0.091899   \n",
       "3       4.549063   3.928844  261.770905 -54.965539  0.146773    0.146296   \n",
       "4       7.995923   6.302023  261.525699 -54.304340  0.307969    0.232219   \n",
       "...          ...        ...         ...        ...       ...         ...   \n",
       "49995   8.085994  13.512841  201.222372 -55.945179  0.125915    0.326936   \n",
       "49996  11.718694   7.443775  202.040730 -54.277964  0.256131    0.286796   \n",
       "49997  25.734570  15.305327  202.492182 -54.246797  0.577675    0.490129   \n",
       "49998   1.195783   1.148171  202.738866 -55.257337  0.023952    0.030967   \n",
       "49999   7.030988   6.196191  202.765541 -55.994185  0.104035    0.151344   \n",
       "\n",
       "       raddflag  wdflag       objID  \n",
       "0             1       0  1244322854  \n",
       "1             1       0  1247347547  \n",
       "2             1       0  1248828237  \n",
       "3             1       0  1247346996  \n",
       "4             1       0  1244321199  \n",
       "...         ...     ...         ...  \n",
       "49995         1       0   848094308  \n",
       "49996         1       0   853812771  \n",
       "49997         1       0   853813897  \n",
       "49998         1       0   855564392  \n",
       "49999         1       0   854308407  \n",
       "\n",
       "[50000 rows x 125 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from hipscat_import.catalog.file_readers import CsvReader\n",
    "\n",
    "input_file=\"/data3/epyc/data3/hipscat/raw/tic_csv/tic_dec56_00S__54_00S.csv.gz\"\n",
    "\n",
    "## This input CSV file requires header and type data from another source.\n",
    "type_frame = pd.read_csv(\"/astro/users/mmd11/git/hipscripts/epyc/allwise/tic_types.csv\")\n",
    "type_names = type_frame[\"name\"].values.tolist()\n",
    "type_map = dict(zip(type_frame[\"name\"], type_frame[\"type\"]))\n",
    "\n",
    "file_reader = CsvReader(\n",
    "                    header=None,\n",
    "                    column_names=type_frame[\"name\"].values.tolist(),\n",
    "                    type_map=type_map,\n",
    "                    chunksize=50_000\n",
    "                )\n",
    "\n",
    "data_frame = next(file_reader.read(input_file))\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156d021",
   "metadata": {},
   "source": [
    "Now that we have the typed data from the input file, write out only the column-level schema to a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e357e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "schema_only_file = \"/data3/epyc/data3/hipscat/tmp/tic_schema.parquet\"\n",
    "pq.write_table(pa.Table.from_pandas(data_frame).schema.empty_table(), where=schema_only_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7ced7",
   "metadata": {},
   "source": [
    "## What next?\n",
    "\n",
    "Add a reference to this new schema only file with the `use_schema_file`.\n",
    "\n",
    "### Unsupported cast\n",
    "\n",
    "Set `resume=True`, then restart your pipeline, and any reduce stages that previously failed will re-run, using this new schema file as column-level metadata.\n",
    "\n",
    "### Unequal schema\n",
    "\n",
    "In the case of the unequal schema in the final stages when writing the `_common_metadata` file, you'll need all your partitioned parquet files to have the same metadata before you try to resume your pipeline.\n",
    "\n",
    "You can:\n",
    "\n",
    "- re-generate the full output by running the pipeline from scratch\n",
    "- re-write the mismatching files with the appropriate schema\n",
    "\n",
    "The below code snippet will look for mismatched files, apply the schema from `schema_only_file`, and overwrite the original file. \n",
    "\n",
    "**Use with caution** - The line to overwrite the files has been commented out to keep folks from blindly running every cell in this notebook and overwriting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Melissa LSDB",
   "language": "python",
   "name": "lsd2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
